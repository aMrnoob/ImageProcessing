import streamlit as st
import cv2
import numpy as np
from keras.models import load_model
from keras.preprocessing.image import img_to_array
from PIL import ImageFont, ImageDraw, Image

def run():
    st.title("üé≠ Nh·∫≠n d·∫°ng c·∫£m x√∫c")

    # Ki·ªÉm tra n·∫øu m√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c t·∫£i v√†o session_state
    if 'is_load' not in st.session_state:
        # T·∫£i m√¥ h√¨nh nh·∫≠n di·ªán c·∫£m x√∫c
        classifier = load_model(r"Nhan_Dang_Cam_Xuc\emotion_detection.h5")
        st.session_state.classifier = classifier

        # ƒê·ªãnh nghƒ©a c√°c nh√£n c·∫£m x√∫c
        class_labels = ['Gi·∫≠n d·ªØ', 'Gh√™ s·ª£', 'S·ª£ h√£i', 'H·∫°nh ph√∫c', 'Bu·ªìn', 'B·∫•t ng·ªù', 'B√¨nh th∆∞·ªùng']
        st.session_state.class_labels = class_labels

        # C√†i ƒë·∫∑t camera
        face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        st.session_state.face_classifier = face_classifier

        # ƒê√°nh d·∫•u ƒë√£ t·∫£i xong
        st.session_state.is_load = True

    # B·∫≠t/t·∫Øt camera
    camera_on = st.checkbox("B·∫≠t/T·∫Øt Camera")
    if camera_on:
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            st.error("Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi camera. Vui l√≤ng ki·ªÉm tra l·∫°i.")
            return

        stframe = st.empty()

        while True:
            ret, frame = cap.read()
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = st.session_state.face_classifier.detectMultiScale(gray, 1.3, 5)

            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                roi_gray = gray[y:y + h, x:x + w]
                roi_gray = cv2.resize(roi_gray, (48, 48), interpolation=cv2.INTER_AREA)

                if np.sum([roi_gray]) != 0:
                    roi = roi_gray.astype('float') / 255.0
                    roi = img_to_array(roi)
                    roi = np.expand_dims(roi, axis=0)

                    preds = st.session_state.classifier.predict(roi)[0]
                    label = st.session_state.class_labels[preds.argmax()]

                    # V·∫Ω vƒÉn b·∫£n l√™n h√¨nh
                    font = ImageFont.truetype("./arial.ttf", 20)
                    img_pil = Image.fromarray(frame)
                    draw = ImageDraw.Draw(img_pil)
                    text_position = (x, y - 40) if y - 40 > 0 else (x, y + h + 10)
                    draw.text(text_position, label, font=font, fill=(0, 255, 0))

                    frame = np.array(img_pil)

            stframe.image(frame, channels="BGR")

            # Tho√°t khi nh·∫•n 'q'
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()
